{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e0f0ed0-8772-47a2-bdb3-f13c0861442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bc547",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#pip install keras==2.11.0 tensorflow>=2.10.0,<3.0.0 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.11.0 (from -r requirements.txt (line 1))\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow<3.0.0,>=2.10.0 (from -r requirements.txt (line 2))\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: libmagic in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.3.11)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.3.10)\n",
      "Requirement already satisfied: langchain_huggingface in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.1.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.26.5)\n",
      "Requirement already satisfied: onnxruntime==1.17.1 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.17.1)\n",
      "Requirement already satisfied: chromadb==0.5.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (0.5.0)\n",
      "Requirement already satisfied: tiktoken==0.7.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
      "Requirement already satisfied: python-magic-bin==0.4.14 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 14)) (0.4.14)\n",
      "Requirement already satisfied: torch in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (2.5.1)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (4.47.0)\n",
      "Requirement already satisfied: unstructured[pdf] in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.16.11)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from onnxruntime==1.17.1->-r requirements.txt (line 9)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from onnxruntime==1.17.1->-r requirements.txt (line 9)) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.26.4 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from onnxruntime==1.17.1->-r requirements.txt (line 9)) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from onnxruntime==1.17.1->-r requirements.txt (line 9)) (24.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from onnxruntime==1.17.1->-r requirements.txt (line 9)) (5.29.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from onnxruntime==1.17.1->-r requirements.txt (line 9)) (1.13.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (1.2.2.post1)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (0.115.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r requirements.txt (line 11)) (0.32.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (3.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (4.12.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (1.28.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (1.68.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from chromadb==0.5.0->-r requirements.txt (line 11)) (3.10.12)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from tiktoken==0.7.0->-r requirements.txt (line 12)) (2024.11.6)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2)) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2)) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\win10\\desktop\\langchianproject\\langchainproject\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2)) (1.17.0)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow-intel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow<3.0.0,>=2.10.0 (from -r requirements.txt (line 2))\n",
      "  Using cached tensorflow-2.17.1-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.17.1 (from tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorflow_intel-2.17.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.1->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached h5py-3.12.1-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.1->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting protobuf (from onnxruntime==1.17.1->-r requirements.txt (line 9))\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.1->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<3.0.0,>=2.10.0 (from -r requirements.txt (line 2))\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorflow<3.0.0,>=2.10.0 (from -r requirements.txt (line 2))\n",
      "  Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.16.2 (from tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.2->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached ml_dtypes-0.3.2-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.2->tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<3.0.0,>=2.10.0 (from -r requirements.txt (line 2))\n",
      "  Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow<3.0.0,>=2.10.0->-r requirements.txt (line 2))\n",
      "  Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested keras==2.11.0\n",
      "    tensorflow-intel 2.16.1 depends on keras>=3.0.0\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install keras==2.11.0 and tensorflow because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4be625-ef8b-429f-921c-7bf85df83edc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from keys import LANGCHAIN_API_KEY , HUGGINGFACEHUB_API_TOKEN\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5d2dff-cdac-417e-9cec-320272adfdf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c3db2-d58e-41e4-989d-030a3c780e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_16184\\3173133658.py:2: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm=HuggingFaceHub(repo_id=\"meta-llama/Llama-3.2-1B\",\n",
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_16184\\3173133658.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt,\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=HuggingFaceHub(repo_id=\"meta-llama/Llama-3.2-1B\", \n",
    "                                        model_kwargs={\"Temperature\":0, \n",
    "                                                      \n",
    "                                                      \"max_length\":64}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270feba9-c2c2-4b9e-a24a-dea4457601bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_16184\\579392319.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm_chain.run(question))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of Egypt?\n",
      "\n",
      "Answer:  Cairo\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "question=\"What is the capital of Egypt?\"\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7053f4a4-b585-45d9-b520-cd53e113ed3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain2 = LLMChain(prompt=prompt, \n",
    "                     llm=HuggingFaceHub(repo_id=\"google/flan-t5-large\", \n",
    "                                        model_kwargs={\"max_length\":64}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bec435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajo@aol.com\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "question=\"what is the email of the employee Alice Johnson\"\n",
    "print(llm_chain2.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11514cad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'context'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m question\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is Liam White hiring date?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm_chain2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\win10\\Desktop\\LangchianProject\\LangchainProject\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\win10\\Desktop\\LangchianProject\\LangchainProject\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:606\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\win10\\Desktop\\LangchianProject\\LangchainProject\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\win10\\Desktop\\LangchianProject\\LangchainProject\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\win10\\Desktop\\LangchianProject\\LangchainProject\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\win10\\Desktop\\LangchianProject\\LangchainProject\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    153\u001b[0m     inputs,\n\u001b[0;32m    154\u001b[0m     run_id,\n\u001b[0;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    156\u001b[0m )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\win10\\Desktop\\LangchianProject\\LangchainProject\\.venv\\Lib\\site-packages\\langchain\\chains\\base.py:290\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    288\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'context'}"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "question=\"what is Liam White hiring date?\"\n",
    "print(llm_chain2.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49394121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"data\",glob=\"*.pdf\",show_progress=True)\n",
    "doc = loader.load()\n",
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0622abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 document(s) into 20 chunks.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "chunks = text_splitter.split_documents(doc)\n",
    "print(f\"Split {len(doc)} document(s) into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bab3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 20 chunks to chroma.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_16184\\3231597218.py:15: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import shutil\n",
    "\n",
    "CHROMA_PATH =\"chroma\"\n",
    "\n",
    "# Clear out the database first if exist.\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "# Create a new DB from the documents.\n",
    "db = Chroma.from_documents(\n",
    "    chunks, HuggingFaceEmbeddings(), persist_directory=CHROMA_PATH\n",
    ")\n",
    "db.persist()\n",
    "print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2043cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query_text = \"what is the email of the employee Alice Johnson\"\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "retrieved_docs = retriever.invoke(query_text)\n",
    "len(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b817007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Use the following retrieved context to answer the query:\n",
      "\n",
      "Employee Details Employ ee Name\n",
      "\n",
      "Role\n",
      "\n",
      "Departme nt\n",
      "\n",
      "Email Address\n",
      "\n",
      "Hire Date\n",
      "\n",
      "Alice Johnson\n",
      "\n",
      "Software Engineer\n",
      "\n",
      "Developm ent\n",
      "\n",
      "alice.johnson@infra tech.com\n",
      "\n",
      "2022-03-15\n",
      "\n",
      "Bob Smith\n",
      "\n",
      "Marketing Manager\n",
      "\n",
      "---\n",
      "\n",
      "Employee Information Report This document contains detailed information about the employees of InfraTech. It includes their names, roles, departments, contact information, and hire dates. In this\n",
      "\n",
      "---\n",
      "\n",
      "Marketing Manager\n",
      "\n",
      "Marketing bob.smith@infratec h.com\n",
      "\n",
      "2020-07-23\n",
      "\n",
      "Charlie Brown\n",
      "\n",
      "Project Manager\n",
      "\n",
      "Operations charlie.brown@infr\n",
      "\n",
      "atech.com\n",
      "\n",
      "2021-05-10\n",
      "\n",
      "Diana William s\n",
      "\n",
      "HR Specialist\n",
      "\n",
      "Query: what is the email of the employee Alice Johnson\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Use the following retrieved context to answer the query:\n",
    "\n",
    "{context}\n",
    "\n",
    "Query: {query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt_format = prompt_template.format(context=context_text, query=query_text)\n",
    "print(prompt_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c714aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: alice.johnson@infra tech.com\n",
      "Sources: ['data\\\\InfraTech_Employee_Information_Report.pdf', 'data\\\\InfraTech_Employee_Information_Report.pdf', 'data\\\\InfraTech_Employee_Information_Report.pdf']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create the LLM chain\n",
    "# Initialize the LLM from Hugging Face Hub\n",
    "llm_chain3 = LLMChain(prompt=prompt_template, \n",
    "                      llm=HuggingFaceHub(\n",
    "                        repo_id=\"google/flan-t5-large\",\n",
    "                        model_kwargs={\"max_length\": 64, \"temperature\": 0.5})  \n",
    "                      )\n",
    "\n",
    "# Run the chain with context and query\n",
    "response_text = llm_chain3.run({\"context\": context_text, \"query\": query_text})\n",
    "\n",
    "# Extract sources from metadata\n",
    "sources = [doc.metadata.get(\"source\", None) for doc in retrieved_docs]\n",
    "\n",
    "# Format the response\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "print(formatted_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
